---
title: "STA-380-Homework-1-Dalton-Haines-Jansen-Karnes"
output: html_document
---
Contributors: Reed Dalton, Corey Haines, Alex Jansen, McKenna Karnes
```{r include = FALSE}
library(fImport)
library(mosaic)
library(foreach)
library(quantmod)
library(cluster)
library(ggplot2)
library(flexclust)
options("getSymbols.warning4.0"=FALSE)
options("getSymbols.yahoo.warning"=FALSE)
set.seed(1)

```



#Probability Practice

### Part A. 
Given a single survey question to visitors to a particular website, what fraction of people who truthfully answered the question answered yes?      
* There are two types of clickers: Random Clickers (RC), and Truthful Clickers (TC)     
* There are two answers to the survey: yes and no   
* The expected fraction of Random Clickers (RC) is 0.3     
* The expected fraction of Truthful Clickers (TC) is 0.7     
* The probability that the Random Clickers (RC) selects yes is .5   
* The probability that the Random Clickers (RC) selects no is .5      
The results of the survey were such that 65% said Yes and 35% said No.          
```{r}
prob.yes = 0.65
prob.no = 0.35
prob.yes.given.RC = 0.5
prob.no.given.RC = 0.5
prob.TC = 0.7
prob.RC = 0.3
prob.yes.given.TC = (prob.yes - (prob.RC * prob.yes.given.RC))/prob.TC

```
`prob.yes` = `prob.TC` \* `prob.yes.given.TC` + `prob.RC` \* `prob.yes.given.RC`

The percentage of Truthful Clickers who answered "Yes" to the the simple survey is `r prob.yes.given.TC`

### Part B.
Medical test for disease using Bayes Formula. 
* The sensitivity is about 0.993. That is, if someone has the disease, there is a probability of 0.993 that they will test positive.     
* The specificity is about 0.9999. This means that if someone doesn't have the disease, there is probability of 0.9999 that they will test negative.     
* About 0.0025% of all people in the general population have the disease
If someone tests positive for the disease, what is the probability they actually have the disease?

```{r}
pop.infected = 0.000025
pop.clean = 0.999975

infected.pos = 0.993
infected.neg = 0.007

clean.pos = 0.0001
clean.neg = 0.9999
infected.test.pos = (infected.pos*pop.infected)/(infected.pos*pop.infected + clean.pos*pop.clean)
infected.test.pos = infected.test.pos * 100

```
If someone tested positive for the disease, there is only a `r infected.test.pos`% chance that they actually have the disease.  
 
Given our calculations, implementing a universal testing policy for this disease would be problematic because over 80% of the time a test for the disease is positive, the person will not actually be infected. This could lead to mass hysteria and put unneeded strain on the population's health systems.       

#Exploratory Analysis: Green Buildings     
* The baseline construction costs are $100 million, with a 5% expected premium for green certification.     
```{r}
#setwd('/Users/Reeddalton/Documents/GitHub/STA-380-Homework-1-Dalton-Haines-Jansen-Karnes')
GreenBuildings = read.csv('greenbuildings.csv')


```

#Bootstrapping and ETF Returns
* To understand the tradeoffs of risk and return of Exchange Traded Funds, we explored the growth over several years of historical data of the following ETFs:
    + US domestic equities (SPY: the S&P 500 stock index)      
    + US Treasury bonds (TLT)      
    + Investment-grade corporate bonds (LQD)     
    + Emerging-market equities (EEM)      
    + Real estate (VNQ)     
* We considered three portfolios with varying levels of risk:
    +Even Split: 20% of  assets in each of the five ETFs      
    + Safer Split: investments  assets in at least three classes      
    + Aggresive Split: consolidating assets into fewer classes with the promise of higher returns at the cost of accepting greater risk   
* We have assumed the portfolio is rebalanced for free each day i.e. with zero transaction costs
```{r}


#Import the stocks
mystocks = c("SPY", "TLT", "LQD", "EEM", "VNQ")
getSymbols(mystocks)

#Adjust for splits and dividends
SPYa = adjustOHLC(SPY)
TLTa = adjustOHLC(TLT)
LQDa = adjustOHLC(LQD)
EEMa = adjustOHLC(EEM)
VNQa = adjustOHLC(VNQ)

```
#Marshals appropriate evidence
I think we need to do some sort of visualization here to show why bonds and the s&p500 are 'safe' investments, while real estate and emerging markets are 'risky' investments.
```{r}
SPYa.adj <- SPYa[,6]
TLTa.adj <- TLTa[,6]
LQDa.adj <- LQDa[,6]
EEMa.adj <- EEMa[,6]
VNQa.adj <- VNQa[,6]

SPYa1 = as.numeric(SPYa.adj[1])
TLTa1 = as.numeric(TLTa.adj[1])
LQDa1 = as.numeric(LQDa.adj[1])
EEMa1 = as.numeric(EEMa.adj[1])
VNQa1 = as.numeric(VNQa.adj[1])

SPYa.ts =SPYa.adj/SPYa1
TLTa.ts =TLTa.adj/TLTa1
LQDa.ts =LQDa.adj/LQDa1
EEMa.ts =EEMa.adj/EEMa1
VNQa.ts =VNQa.adj/VNQa1

basket <- cbind(SPYa.ts,TLTa.ts,LQDa.ts,EEMa.ts,VNQa.ts  )
zoo.basket <- as.zoo(basket)
tsRainbow <- rainbow(ncol(zoo.basket))
plot(x = zoo.basket, ylab = "Cumulative Return", main = "Cumulative Returns",col = tsRainbow, screens = 1)
legend(x = "topleft", legend = c("SPY", "TLT", "LQD", "EEM", "VNQ"), lty = 1,col = tsRainbow)



```





###Even Split Portfolio

```{r}
#############################
#########Even Split Portfolio
#############################

#Setting up an all returns matrix showing closing prices for each day 
all_returns = cbind(ClCl(SPYa),ClCl(TLTa),ClCl(LQDa), ClCl(EEMa), ClCl(VNQa))
all_returns = as.matrix(na.omit(all_returns))

n_days = 20#i.e. four weeks

#Setting up the Even Split Portfolio and using Bootstrap to find VaR
initial.wealth = 100000
sim.even = foreach(i=1:5000, .combine = 'rbind')%do%{
  days = 20
  total.wealth = initial.wealth
  even.weight = c(0.2,0.2,0.2,0.2,0.2)
  even.holdings = even.weight*total.wealth
  even.wealthtracker = rep(0,days)
  #loop over four trading weeks
  for(today in 1:days){
    return.today = resample(all_returns, 1, orig.ids = FALSE)
    even.holdings = even.holdings + even.holdings*return.today
    total.wealth = sum(even.holdings)
    even.wealthtracker[today] = total.wealth
  }
  even.wealthtracker
}

#Calculate 5% VaR for even portfolio
even.split.VaR = quantile(sim.even[,n_days], 0.05) - initial.wealth
print(sprintf('The value at risk at the five percent level for our even split portfolio is %f: ', even.split.VaR))
```


###Safer Split
```{r}
##################
###### Safer Split
##################

safe_returns = cbind(ClCl(SPYa),ClCl(TLTa),ClCl(LQDa))
safe_returns = as.matrix(na.omit(safe_returns))

#Setting up the Safe Split Portfolio and using Bootstrap to find VaR

initial.wealth = 100000

sim.safe = foreach(i=1:5000, .combine = 'rbind')%do%{
  days = 20
  total.wealth = initial.wealth
  safe.weight = c(1/3,1/3,1/3)
  safe.holdings = safe.weight*total.wealth
  safe.wealthtracker = rep(0,days)
  #loop over four trading weeks
  for(today in 1:days){
    return.today = resample(safe_returns, 1, orig.ids = FALSE)
    safe.holdings = safe.holdings + safe.holdings*return.today
    total.wealth = sum(safe.holdings)
    safe.wealthtracker[today] = total.wealth
  }
  safe.wealthtracker
}

#Calculate 5% VaR for safe portfolio
safe.split.VaR = quantile(sim.safe[,n_days], 0.05) - initial.wealth
print(sprintf('The value at risk at the five percent level for our safe split portfolio is %f: ', safe.split.VaR))
```


##Aggressive Portfolio
```{r}
########################
####Aggressive Portfolio
########################
aggressive_returns = cbind(ClCl(EEMa),ClCl(VNQa))
aggressive_returns = as.matrix(na.omit(aggressive_returns))

#Setting up the Agressive Split Portfolio and using Bootstrap to find VaR

initial.wealth = 100000

sim.aggressive = foreach(i=1:5000, .combine = 'rbind')%do%{
  days = 20
  total.wealth = initial.wealth
  aggressive.weight = c(1/2,1/2)
  aggressive.holdings = aggressive.weight*total.wealth
  aggressive.wealthtracker = rep(0,days)
  #loop over four trading weeks
  for(today in 1:days){
    return.today = resample(aggressive_returns, 1, orig.ids = FALSE)
    aggressive.holdings = aggressive.holdings + aggressive.holdings*return.today
    total.wealth = sum(aggressive.holdings)
    aggressive.wealthtracker[today] = total.wealth
  }
  aggressive.wealthtracker
}

#Calculate 5% VaR for aggressive portfolio
aggressive.split.VaR = quantile(sim.aggressive[,n_days], 0.05) - initial.wealth
print(sprintf('The value at risk at the five percent level for our aggressive split portfolio is %f: ', aggressive.split.VaR))

```


#Market Segmentation and NutrientH2O
```{r}
social_marketing = read.csv('social_marketing.csv')

sm <- social_marketing[,-1]/rowSums(social_marketing[,-1], na.rm = FALSE)
sm = cbind(X = social_marketing[,1], sm)

social_marketing$Total = rowSums(social_marketing[,-1], na.rm = FALSE)

total_tweets_by_category = colSums(social_marketing[,-1], na.rm = FALSE)
sort(total_tweets_by_category)
#pairs(social_marketing[,-1])
```
I created a matrix where I found the proportion that each user tweeted about each category. This was done in an attempt to standardize across the distribution of activity for users. 

I then added the total number of tweets per user to the last column of social_marketing. I then found the total number of tweets for each of the 36 different categories.  

From inspecting the sm dataframe, I am not as concerned about tweets categorized as "spam". No account tweets out more than 2 tweets categorized as spam, and the highest percentage of an account's tweets being categorized as spam is 7%.   

However, "adult" is a little less clear, as there are 2 accounts where half of the tweets are adult. These are probably just horny old men who don't understand how to use twitter and will still consume NutrientH2O, so I think we can leave them in. 

```{r}

apply(social_marketing[,-1] , 2, mean)
pr.out =prcomp(social_marketing[,-1] , scale =TRUE)
#biplot (pr.out , scale =0)
pr.out$rotation
pr.var =pr.out$sdev^2
pve=pr.var/sum(pr.var)
plot(pve , xlab=" Principal Component ", ylab=" Proportion of
Variance Explained ", ylim=c(0,1) ,type='b')
plot(cumsum (pve), xlab=" Principal Component ", ylab ="
Cumulative Proportion of Variance Explained ", ylim=c(0,1) ,
type='b')
```

```{r}
set.seed (3)
km.out =kmeans(social_marketing[,-1],3, nstart =50)
km.out$tot.withinss

#plot(social_marketing[,-1], col =(km.out$cluster +1) , main="K-Means Clustering Results with K=3", pch =20, cex =2)


```

```{r}

data(social_marketing[,-1])
km    <- kmeans(social_marketing[,-1],3)
dissE <- daisy(social_marketing[,-1]) 
dE2   <- dissE^2
sk2   <- silhouette(km$cl, dE2)
plot(sk2)


```


